/**
 * AtenMed - AI Service
 * Servi√ßo de IA conversacional para WhatsApp Bot
 * Suporta: OpenAI GPT e Google Gemini
 */

const axios = require('axios');
const logger = require('../utils/logger');

// ===== CONFIGURA√á√ÉO =====
const AI_PROVIDER = process.env.AI_PROVIDER || 'openai'; // 'openai' ou 'gemini'
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const GEMINI_API_KEY = process.env.GEMINI_API_KEY;

// Contexto do sistema (personalidade do bot)
const SYSTEM_CONTEXT = `Voc√™ √© um assistente virtual amig√°vel da AtenMed, uma cl√≠nica m√©dica brasileira.

PERSONALIDADE:
- Seja extremamente amig√°vel, emp√°tico e prestativo
- Use linguagem casual brasileira (puts, eita, opa, show, legal)
- Seja breve e direto nas respostas
- Use emojis contextuais (mas sem exagero)
- Demonstre entusiasmo em ajudar

RESTRI√á√ïES:
- NUNCA marque consultas diretamente - apenas colete informa√ß√µes
- N√ÉO invente hor√°rios ou disponibilidade - isso √© verificado no sistema
- Se n√£o souber algo, seja honesto e ofere√ßa ajuda humana
- Mantenha foco em agendamento m√©dico

EXEMPLOS DE COMO RESPONDER:
Paciente: "Oi, quero marcar"
Voc√™: "Oi! üòä Legal, vamos marcar uma consulta! Pra qual especialidade voc√™ precisa? Cardiologia, Cl√≠nica Geral, Odontologia...?"

Paciente: "sim"
Voc√™: "Show! Bora ent√£o! üëç"

Paciente: "quero um m√©dico"
Voc√™: "Claro! Vamos te ajudar! Qual especialidade voc√™ precisa? üòä"

IMPORTANTE: Seja sempre positivo, acolhedor e eficiente!`;

// ===== INICIALIZA√á√ÉO =====
function initialize() {
    if (AI_PROVIDER === 'openai' && !OPENAI_API_KEY) {
        logger.warn('‚ö†Ô∏è OpenAI API Key n√£o configurada. IA desabilitada.');
        return false;
    }
    
    if (AI_PROVIDER === 'gemini' && !GEMINI_API_KEY) {
        logger.warn('‚ö†Ô∏è Gemini API Key n√£o configurada. IA desabilitada.');
        return false;
    }
    
    logger.info(`ü§ñ AI Service inicializado com ${AI_PROVIDER.toUpperCase()}`);
    return true;
}

// ===== PROCESSAR MENSAGEM COM IA =====
async function processMessage(userMessage, conversationHistory = []) {
    try {
        if (AI_PROVIDER === 'openai') {
            return await processWithOpenAI(userMessage, conversationHistory);
        } else if (AI_PROVIDER === 'gemini') {
            return await processWithGemini(userMessage, conversationHistory);
        }
        
        return null;
    } catch (error) {
        logger.error('Erro ao processar com IA:', error);
        return null;
    }
}

// ===== OPENAI GPT =====
async function processWithOpenAI(userMessage, conversationHistory) {
    if (!OPENAI_API_KEY) return null;
    
    try {
        const messages = [
            { role: 'system', content: SYSTEM_CONTEXT },
            ...conversationHistory.map(msg => ({
                role: msg.isUser ? 'user' : 'assistant',
                content: msg.text
            })),
            { role: 'user', content: userMessage }
        ];

        const response = await axios.post(
            'https://api.openai.com/v1/chat/completions',
            {
                model: process.env.OPENAI_MODEL || 'gpt-3.5-turbo',
                messages: messages,
                max_tokens: 200,
                temperature: 0.8,
                presence_penalty: 0.6,
                frequency_penalty: 0.3
            },
            {
                headers: {
                    'Authorization': `Bearer ${OPENAI_API_KEY}`,
                    'Content-Type': 'application/json'
                },
                timeout: 10000
            }
        );

        const aiResponse = response.data.choices[0].message.content;
        logger.info(`ü§ñ OpenAI: ${aiResponse.substring(0, 50)}...`);
        
        return aiResponse;
    } catch (error) {
        logger.error('Erro OpenAI:', error.response?.data || error.message);
        return null;
    }
}

// ===== GOOGLE GEMINI =====
async function processWithGemini(userMessage, conversationHistory) {
    if (!GEMINI_API_KEY) return null;
    
    try {
        // Construir hist√≥rico para Gemini
        let fullContext = SYSTEM_CONTEXT + '\n\nHist√≥rico da conversa:\n';
        
        conversationHistory.forEach(msg => {
            fullContext += `${msg.isUser ? 'Paciente' : 'Voc√™'}: ${msg.text}\n`;
        });
        
        fullContext += `Paciente: ${userMessage}\nVoc√™:`;

        const response = await axios.post(
            `https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${GEMINI_API_KEY}`,
            {
                contents: [{
                    parts: [{
                        text: fullContext
                    }]
                }],
                generationConfig: {
                    temperature: 0.8,
                    maxOutputTokens: 200,
                    topP: 0.8,
                    topK: 40
                }
            },
            {
                headers: {
                    'Content-Type': 'application/json'
                },
                timeout: 10000
            }
        );

        const aiResponse = response.data.candidates[0].content.parts[0].text;
        logger.info(`ü§ñ Gemini: ${aiResponse.substring(0, 50)}...`);
        
        return aiResponse;
    } catch (error) {
        logger.error('Erro Gemini:', error.response?.data || error.message);
        return null;
    }
}

// ===== AN√ÅLISE DE INTEN√á√ÉO =====
async function analyzeIntent(userMessage) {
    try {
        const intentPrompt = `Analise a inten√ß√£o do usu√°rio e responda APENAS com uma destas op√ß√µes:
- agendar: quer marcar consulta
- consultar: quer ver agendamentos
- cancelar: quer cancelar
- confirmar: est√° confirmando algo (sim, ok, confirmo)
- negar: est√° negando algo (n√£o, nao)
- ajuda: precisa de ajuda/atendente
- saudacao: est√° cumprimentando
- numero: digitou apenas um n√∫mero
- outro: outra coisa

Mensagem do usu√°rio: "${userMessage}"

Responda APENAS com uma palavra (agendar, consultar, etc):`;

        if (AI_PROVIDER === 'openai' && OPENAI_API_KEY) {
            const response = await axios.post(
                'https://api.openai.com/v1/chat/completions',
                {
                    model: 'gpt-3.5-turbo',
                    messages: [
                        { role: 'system', content: 'Voc√™ √© um classificador de inten√ß√µes.' },
                        { role: 'user', content: intentPrompt }
                    ],
                    max_tokens: 10,
                    temperature: 0.3
                },
                {
                    headers: {
                        'Authorization': `Bearer ${OPENAI_API_KEY}`,
                        'Content-Type': 'application/json'
                    },
                    timeout: 5000
                }
            );

            const intent = response.data.choices[0].message.content.trim().toLowerCase();
            logger.info(`üéØ Inten√ß√£o detectada: ${intent}`);
            return intent;
            
        } else if (AI_PROVIDER === 'gemini' && GEMINI_API_KEY) {
            const response = await axios.post(
                `https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${GEMINI_API_KEY}`,
                {
                    contents: [{ parts: [{ text: intentPrompt }] }],
                    generationConfig: { maxOutputTokens: 10, temperature: 0.3 }
                },
                {
                    headers: { 'Content-Type': 'application/json' },
                    timeout: 5000
                }
            );

            const intent = response.data.candidates[0].content.parts[0].text.trim().toLowerCase();
            logger.info(`üéØ Inten√ß√£o detectada: ${intent}`);
            return intent;
        }
        
        return 'outro';
    } catch (error) {
        logger.error('Erro ao analisar inten√ß√£o:', error.message);
        return 'outro';
    }
}

// ===== EXTRAIR INFORMA√á√ïES =====
async function extractInformation(userMessage, infoType) {
    try {
        let extractPrompt = '';
        
        switch (infoType) {
            case 'name':
                extractPrompt = `Extraia APENAS o nome da pessoa desta mensagem. Se n√£o houver nome, responda "NENHUM".
Mensagem: "${userMessage}"
Nome:`;
                break;
                
            case 'date':
                extractPrompt = `Extraia APENAS a data desta mensagem no formato DD/MM/AAAA. Se n√£o houver data v√°lida, responda "NENHUM".
Mensagem: "${userMessage}"
Data:`;
                break;
                
            case 'specialty':
                extractPrompt = `Identifique a especialidade m√©dica mencionada. Op√ß√µes: cardiologia, clinica geral, odontologia, ortopedia, pediatria.
Se n√£o identificar ou for outra, responda "NENHUM".
Mensagem: "${userMessage}"
Especialidade:`;
                break;
                
            default:
                return null;
        }

        if (AI_PROVIDER === 'openai' && OPENAI_API_KEY) {
            const response = await axios.post(
                'https://api.openai.com/v1/chat/completions',
                {
                    model: 'gpt-3.5-turbo',
                    messages: [
                        { role: 'system', content: 'Voc√™ extrai informa√ß√µes espec√≠ficas de mensagens.' },
                        { role: 'user', content: extractPrompt }
                    ],
                    max_tokens: 50,
                    temperature: 0.3
                },
                {
                    headers: {
                        'Authorization': `Bearer ${OPENAI_API_KEY}`,
                        'Content-Type': 'application/json'
                    },
                    timeout: 5000
                }
            );

            const extracted = response.data.choices[0].message.content.trim();
            return extracted === 'NENHUM' ? null : extracted;
        }
        
        return null;
    } catch (error) {
        logger.error('Erro ao extrair informa√ß√£o:', error.message);
        return null;
    }
}

// ===== VERIFICAR SE DEVE USAR IA =====
function shouldUseAI() {
    return (AI_PROVIDER === 'openai' && OPENAI_API_KEY) || 
           (AI_PROVIDER === 'gemini' && GEMINI_API_KEY);
}

// ===== ESTAT√çSTICAS =====
let stats = {
    totalRequests: 0,
    successfulRequests: 0,
    failedRequests: 0,
    avgResponseTime: 0
};

function getStats() {
    return {
        ...stats,
        provider: AI_PROVIDER,
        enabled: shouldUseAI(),
        successRate: stats.totalRequests > 0 
            ? ((stats.successfulRequests / stats.totalRequests) * 100).toFixed(1) + '%'
            : '0%'
    };
}

// ===== EXPORTAR =====
module.exports = {
    initialize,
    processMessage,
    analyzeIntent,
    extractInformation,
    shouldUseAI,
    getStats
};

